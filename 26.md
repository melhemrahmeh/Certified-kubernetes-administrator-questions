### **Q.26 - Mark `kworker` as Unschedulable and Reschedule Pods**
#### **Task:**
1. **Mark the worker node `kworker` as unschedulable**.
2. **Reschedule all pods running on `kworker`**.

---

### **1. Cordon the Node (`kworker`)**
Cordoning will mark the node as **unschedulable**, preventing new pods from being scheduled.
```sh
kubectl cordon kworker
```
Expected output:
```
node/kworker cordoned
```
- This prevents new pods from being scheduled on `kworker`, but does not affect running pods.

---

### **2. Drain the Node (`kworker`)**
Draining will **evict all pods** and allow them to be rescheduled on other nodes.
```sh
kubectl drain kworker --ignore-daemonsets --delete-emptydir-data
```
- `--ignore-daemonsets`: Ensures that daemonset pods are not removed.
- `--delete-emptydir-data`: Ensures pods using `emptyDir` volumes can be deleted.

Expected output:
```
node/kworker cordoned
evicting pod default/pod-name-1
evicting pod default/pod-name-2
...
```
Once completed, `kworker` will have **no running non-daemonset pods**.

---

### **3. Verify the Node and Pods**
Check the node status:
```sh
kubectl get nodes
```
- `kworker` should be marked as `SchedulingDisabled`.

Check pod distribution:
```sh
kubectl get pods -o wide
```
- Ensure all previously running pods on `kworker` are now running on other nodes.

---

### **4. Uncordon the Node (if needed)**
To **make `kworker` schedulable again**, run:
```sh
kubectl uncordon kworker
```
Expected output:
```
node/kworker uncordoned
```
- This allows new pods to be scheduled on `kworker` again.

---

### **Conclusion**
**Marked `kworker` as unschedulable using `cordon`.**  
**Evicted and rescheduled all pods using `drain`.**  
**Optionally allowed scheduling again with `uncordon`.**  
**Pods are successfully rescheduled to other nodes!**